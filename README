# Symbolic Regression with Genetic Programming and Transfer Learning

## Overview
This project implements a **Genetic Programming (GP)** algorithm in Java to perform symbolic regression. The goal of the system is to predict computer performance based on CPU specifications. 

A key feature of this implementation is the exploration of **Transfer Learning**. The model is first trained on a smaller, lower-dimensional dataset (`227_cpu_small.tsv`) to evolve a baseline solution. This solution is then "transferred" to a new GP instance to accelerate learning on a larger, more complex dataset (`197_cpu_act.tsv`).

**Course:** COS710 - Assignment 2  
**Language:** Java

## Features
* **Custom Genetic Programming Engine:** A scratch implementation of tree-based GP, including node generation (terminal/functional), fitness evaluation, and tree constraints.
* **Transfer Learning Pipeline:** Automates the process of extracting the best phenotype from a source domain and seeding it into the target domain population.
* **Evolutionary Operators:**
    * **Selection:** Tournament Selection to prevent premature convergence.
    * **Crossover:** Subtree crossover exchanges genetic material between parents.
    * **Mutation:** Point mutation changes specific nodes (operators or terminals) to maintain diversity.
* **Parameter Tuning:** Includes extensive test suites (`Main.java`) for tuning epochs, population size, tree depth, and split ratios.

## Project Structure
The repository consists of the following core Java files:

### 1. `GP.java`
The core engine for the Genetic Programming algorithm. It handles:
* **Population Management:** Initialization and generational evolution.
* **Training Loop:** `train()` handles the evolutionary cycle (Selection -> Crossover/Mutation -> Evaluation).
* **Testing:** Evaluates the best tree against unseen test data.
* **Fitness Function:** Calculates Mean Absolute Error (MAE) against target CPU performance values.

### 2. `GPTransffered.java`
A wrapper class designed to manage the Transfer Learning workflow:
* **`trainGP()`**: Runs the initial training on the small dataset.
* **`transferAndCreate()`**: Takes the best tree from the initial run and initializes a new population. It supports configuring the ratio of **copies**, **mutants** (mutated versions of the best tree), and **new random trees** in the next generation.
* **`trainGPT()`**: Retrains the population on the larger dataset using the transferred knowledge.

### 3. `Main.java`
The entry point for the application. It contains:
* **`singleTransferRun()`**: Executes a complete pipeline: Train Source -> Transfer -> Train Target.
* **`paramTuneTest()`**: A suite of automated tests to evaluate the impact of different hyperparameters (Epochs, Size, Depth, Split).
* **`transferTest()`**: Runs statistical validation (e.g., 10 runs) to calculate average MAE and Standard Deviation.

*Note: This repository requires additional helper classes (`Tree`, `Node`, `Population`, `CSVReader`) and dataset files to compile and run successfully.*

## Algorithm Details

### The Evolutionary Process
The GP follows a standard evolutionary cycle:
1.  **Initialization:** Trees are generated using the "grow" method up to a specified max depth.
2.  **Evaluation:** Trees are evaluated based on Mean Absolute Error (MAE) (lower is better).
3.  **Selection:** Tournament selection chooses parents for the next generation.
4.  **Reproduction:**
    * **Crossover (70%)**: Swaps subtrees between two parents.
    * **Mutation (30%)**: Randomly alters a node in a parent tree.
5.  **Termination:** Stops after a set number of epochs or if the solution stagnates.

### Transfer Strategy
To handle the increase in complexity between the small and large datasets:
1.  Run the GP on the small dataset (12 variables).
2.  Extract the best-performing tree.
3.  Seed the population for the large dataset (20 variables) with:
    * **25%** Direct copies of the transferred tree.
    * **50%** Mutated versions of the transferred tree (to introduce new variables from the larger dataset).
    * **25%** Entirely new random trees (to maintain diversity).

## Configuration
The hyperparameters for the Transfer GP run are optimized as follows:

| Parameter | Value |
| :--- | :--- |
| **Epochs** | 250 |
| **Population Size** | 250 |
| **Max Depth** | 7 |
| **Crossover/Mutation Split** | 0.7 / 0.3 |
| **Train/Test Split** | 0.7 / 0.3 |

## Results
The implementation successfully demonstrated that transfer learning improves stability and performance when moving to higher-dimensional data.
* **Average MAE:** ~4.2855
* **Best MAE Achieved:** 3.1816
* **Standard Deviation:** 1.0229 (indicating consistent convergence)

## Usage
To run a single transfer experiment:
1.  Ensure all dependent classes (`Tree`, `Node`, `Population`, `CSVReader`) are in the source path.
2.  Place `227_cpu_small.tsv` and `197_cpu_act.tsv` in the project root.
3.  Compile and run `Main.java`:

```bash
javac Main.java
java Main
